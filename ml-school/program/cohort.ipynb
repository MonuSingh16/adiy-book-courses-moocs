{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "\n",
    ":::{.callout-note}\n",
    "Before running this notebook, follow the [Setup Instructions](https://program.ml.school/setup.html) for the program.\n",
    ":::\n",
    "\n",
    "Let's start by setting up the environment and preparing to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "import ipytest\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Generating lot of scripts, hence folders to store them\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "INFERENCE_CODE_FOLDER = CODE_FOLDER / \"inference\"\n",
    "INFERENCE_CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# This makes the following files in folder available to python interpreter\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\", f\"./{INFERENCE_CODE_FOLDER}\"])\n",
    "\n",
    "DATA_FILE_PATH = \"penguins.csv\"\n",
    "\n",
    "# It let run the unit test right from the notebook\n",
    "ipytest.autoconfig(raise_on_error=True)\n",
    "\n",
    "# By default, The SageMaker SDK logs events related to the default\n",
    "# configuration using the INFO level. To prevent these from spoiling\n",
    "# the output of this notebook cells, we can change the logging\n",
    "# level to ERROR instead.\n",
    "logging.getLogger(\"sagemaker.config\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run this notebook in [Local Mode](https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-local-mode.html) to test the pipeline in your local environment before using SageMaker. You can run the code in Local Mode by setting the LOCAL_MODE constant to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MODE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the S3 bucket name and the AWS Role from the environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bucket = os.environ[\"BUCKET\"]\n",
    "role = os.environ[\"ROLE\"]\n",
    "\n",
    "S3_LOCATION = f\"s3://{bucket}/penguins\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running the pipeline in Local Mode on an ARM64 machine, you will need to use a custom Docker image to train and evaluate the model. This is because SageMaker doesn't provide a TensorFlow image that supports Apple's M chips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture = !(uname -m)\n",
    "IS_APPLE_M_CHIP = architecture[0] == \"arm64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a configuration dictionary with different settings depending on whether we are running the pipeline in Local Mode or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "from sagemaker.workflow.pipeline_context import PipelineSession, LocalPipelineSession\n",
    "\n",
    "pipeline_session = PipelineSession(default_bucket=bucket) if not LOCAL_MODE else None\n",
    "\n",
    "if LOCAL_MODE:\n",
    "    config = {\n",
    "        \"session\": LocalPipelineSession(default_bucket=bucket),\n",
    "        \"instance_type\": \"local\",\n",
    "        # We need to use a custom Docker image when we run the pipeline\n",
    "        # in Local Model on an ARM64 machine.\n",
    "        \"image\": \"sagemaker-tensorflow-toolkit-local\" if IS_APPLE_M_CHIP else None\n",
    "    }\n",
    "else:\n",
    "    config = {\n",
    "        \"session\": pipeline_session,\n",
    "        \"instance_type\": \"ml.m5.xlarge\",\n",
    "        \"image\": None\n",
    "\n",
    "    }\n",
    "\n",
    "config[\"framework_version\"] = \"2.11\"\n",
    "config[\"py_version\"] = \"py39\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now initialize a few variables that we'll need throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "iam_client = boto3.client(\"iam\")\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
